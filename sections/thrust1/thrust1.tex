%\subsection{Motivating Example: AES encryption algorithm.}

We briefly describe three main challenges in addressing timing attacks in GPU code.
%
Two of these challenges are specific to GPUs.
%
The third is a challenge for CPU security as well, but interacts with the
first two challenges and will need to be handled specially for GPU code.

\paragraph{Challenge 1: GPU-specific timing channels.}
The AES example in Section~\ref{sec:motivating} showed one new timing channel not addressed by prior work on CPUs: bank conflicts are a phenomenon specific to the GPU memory model.
%
While cache effects are a timing channel that exists in CPU code and also depends on locality of memory accesses \stefan{(cite? I assume someone has studied caching as a timing channel)}, bank conflicts behave differently and will need to
be handled differently.
%
For example, suppose~\texttt{h} is a high-security bit (i.e.,~\texttt{h} is known to be 0 or 1).
%
If array \lstinline{S} is stored in shared memory,
the access \lstinline{S[threadIdx.x * h]} has no bank conflicts regardless
of~\texttt{h} and therefore leaks no information through bank conflicts
(if \lstinline{S} contains secret data, it may, of course, leak this data
through other means).
%
Neither does the access \lstinline{S[threadIdx.x * 5 * h]}: because~5
and~32 are relatively prime, even if~\texttt{h = 1}, each thread targets a
different bank, although the locality is much worse.
%
However, the access \lstinline{S[threadIdx.x * 2 * h]}, which has better
locality than the previous code, will result in bank conflicts if~\texttt{h = 1}.

The SIMT execution model of GPUs can also lead to timing channels.
%
Consider the following code:

\begin{lstlisting}
if (h) {
  h = 1;
} else {
  h = 2;
}
\end{lstlisting}

Recall that each thread has a separate copy of local variables, so that
each thread may have a different value for~\texttt{h}.
%
The code results in no insecure information flows through data: only
high-security variables are written.
%
If this code is executing on a CPU using reasonably traditional cost models,
there are also no obvious timing channels: one branch will be taken, but
both should take the same amount of time.
%
However, because all threads of a warp must execute the same instruction at the same time, when a warp evaluates the conditional, if~\texttt{h} is true in some threads and false in others, the GPU must disable the threads where~\texttt{h} is false, run the ``then'' branch, and then swap what threads are active to execute the ``else'' branch.
%
The two branches run sequentially on different sets of threads.
%
This is referred to as a {\em warp divergence}.
%
If~\texttt{h} has the same value on all threads in the warp, however, only
one branch is executed.
%
This means that, when run on a GPU, the above code has a timing leak: by
observing the time taken to execute the code, we can determine whether or not
all threads in the warp have the same value for~\texttt{h}.

\paragraph{Challenge 2: Leaks through the thread mask.}
An additional difficulty in reasoning about GPU code, which is not present in CPU code, is that the security of a code snippet can depend on the current {\em mask}, that is, what threads in a warp are active (which may be a subset of the threads in the warp if there has been a warp divergence).
%
For example, consider the following program in which~\lstinline{h} is a high-security local variable,~\lstinline{S} is an array stored in shared memory, and~\lstinline{threadIdx} is the integer thread identifier of each thread.

\begin{lstlisting}
if (h) {
  S[2 * threadIdx] = 0;
} else {
  S[2 * threadIdx] = 0;
}
\end{lstlisting}

Naively, it would appear that, although this program conditions on the high-security variable~\lstinline{h}, doing so can't leak information because the code in both branches is identical and the shared memory access uses only low-security indices (\lstinline{threadIdx} is considered low-security).
%
However, the program does indeed leak information.
%
Consider an execution in which threads 0--15 take the ``then'' branch and threads 16--31 take the ``else'' branch.
%
In this case, neither branch has a bank conflict, and nor does the program as a whole because the two branches are executed in sequence.
%
On the other hand, consider an execution in which even-number threads take the ``then'' branch and odd-number threads take the ``else'' branch.
%
In this case, both branches have a bank conflict.
%
The leak here is due to the fact that {\em which threads are active} during each branch impacts cost behavior, and this in turn is determined by high-secrecy information.
%

Because GPU programs generally have thousands of threads, reasoning about the local state of individual threads quickly becomes intractable.
%
Muller and Hoffmann~\cite{MullerHo21} observe that a useful middle ground is to instead track which variables are {\em uniform} across all threads and reason precisely only about the local state of these variables.
%
From a cost perspective, this is sufficient in many real-world GPU programs because variables, such as loop indices, that impact cost are generally uniform.
%
We hypothesize that this approximation is useful in a security context as well.
%
For example, in determining that the above program has an information leak, it suffices to know {\em whether}~\lstinline{h} is uniform, because the leak stems from the fact that it may be divergent (i.e., not uniform).


\paragraph{Challenge 3: Quantitative leak analysis.}
Avoiding any possibility of information leaks is too restrictive and also not realistic: in the AES example, it is difficult to imagine any table-based implementation that would not suffer from possible timing attacks; even if preventing these attempts is possible, it would be at the cost of a very slow implementation.
%
However, small differences in the number of bank conflicts may not even be detectable by the attacker given the nondeterministic environment and experimental noise.
%
This suggests there may be some middle ground where the differences in bank conflicts between runs are mitigated to the point where extracting a key based on differences in timing is intractable but the implementation is still reasonable.
%
Moreover, even if the attacker observes some information it is ok if we leak some sort of information (another reason why LLM is a betetr example).
%
If we are too restrictive and avoid every form of leakage, then we cannot train LLM at all. \stefan{This sounds more related to declassification, which we don't address; maybe I'm misreading it.}
%
What we want however, is to ensure that the information that attackers' observations do not increase their chances of guessing private information beyond some acceptable amount.
% The key is fixed. Test it using a given plaintext to find the key.
% Accessing shared memory depends on the key.



%

% AES: shared memory accesses are dependent on the key. 
% %






% As the constant cache stores data
% from constant memory that can be shared by threads
% in a warp, for AES encryption we use this space to store
% round keys.


\subsection{Proposed work}
\input{sections/thrust1/1a.tex}
\input{sections/thrust1/1b.tex}
\input{sections/thrust1/1c.tex}
